## Lecture28 排序算法的理论边界 (Sorting and Algorithmic Bounds)



### 1. 知识点回顾：常见排序算法总结

在深入理论之前，我们先快速回顾一下已经学过的几种排序算法的特性。这有助于我们建立一个“现有技术水平”的参照系。

| **排序算法**             | **空间复杂度**  | **比较次数 (时间复杂度)** | **稳定性** | 关键说明                                           |
| ------------------------ | --------------- | ------------------------- | ---------- | -------------------------------------------------- |
| **堆排序 (Heapsort)**    | Θ(1)            | Θ(N log N)                | 否         | 它的缓存效率不高。                                 |
| **插入排序 (Insertion)** | Θ(1)            | Θ(N^2)                    | 是         | 在处理近乎有序的数组或小规模数据(N<15)时表现最佳。 |
| **归并排序 (Mergesort)** | Θ(N)            | Θ(N log N)                | 是         | 是速度最快的稳定排序算法。                         |
| **快速排序 (Quicksort)** | Θ(log N) (期望) | Θ(N log N) (期望)         | 否         | 通常被认为是速度最快的排序算法。                   |



**总结**：我们已经有了好几个平均或最坏情况时间复杂度为 Θ(N log N) 的算法。现在的问题是：我们能做得更好吗？是否存在一个尚未被发现的、更快的“终极排序算法”？



### 2. 问题的定义：什么是“比较排序”？

为了严谨地探讨排序的理论边界，我们必须明确我们所讨论的算法类型。今天，我们只关注**比较排序 (Comparison Sorts)**。

这类算法遵循两条基本操作规则：

1. **比较 (compareTo)**：通过一个 `compareTo` 函数来比较两个元素的大小，从而得知它们的相对顺序。
2. **交换 (swap)**：交换数组中两个元素的位置。

我们前面提到的**选择排序、插入排序、归并排序、快速排序、堆排序**都属于比较排序。这个限制很重要，因为它意味着算法不能通过查看元素的具体值来“作弊”，而必须通过两两比较来获取信息。



### 3. 核心论证：探寻排序问题的理论下界

我们的目标是找到“终极比较排序算法 (The Ultimate Comparison Sort, TUCS)”的最坏情况运行时间 R(N)。

- **上界 (Upper Bound, O-notation)**：我们已经知道存在最坏时间为 Θ(N log N) 的归并排序，所以 TUCS 的性能不可能比这更差。因此，TUCS 的运行时间是 O(N log N)。

- **下界 (Lower Bound, Ω-notation)**：我们至少要查看每个元素一次，所以一个简单的下界是 Ω(N)。

  

现在，我们的问题变成了：这个下界能否从 Ω(N) 被收紧？答案是肯定的，而证明过程非常巧妙。我们将通过一个类比来理解它。



#### 3.1 类比一：有趣的“猜硬币”谜题

这个谜题能帮助我们理解“信息”和“决策”是如何限制算法步骤的。

**问题**：有9个外观完全相同的硬币，其中一个是假币，比真币稍重。你有一个天平，最多只能称两次，如何找出假币？

**解法**：

1. **第一次称重**：将硬币分为三组 (1,2,3), (4,5,6), (7,8,9)。将前两组放到天平上。
   - **情况A：左重**。假币在 (1,2,3) 中。
   - **情况B：右重**。假币在 (4,5,6) 中。
   - **情况C：平衡**。假币在 (7,8,9) 中。
2. **第二次称重**：以情况A为例，我们已经知道假币是1、2、3中的一个。此时，将硬币1和2放到天平上。
   - **左重**：假币是1。
   - **右重**：假币是2。
   - **平衡**：假币是3。



这个过程可以用一个**决策树 (Decision Tree)** 来表示：



*图例：九硬币问题的决策树。每个天平称重是一个决策节点，有三种可能的结果（左重、右重、平衡），叶子节点代表最终答案。*

<img src="https://pic-go-image-1363881366.cos.ap-chengdu.myqcloud.com/Image/%E6%AF%94%E8%BE%83%E5%86%B3%E7%AD%96%E6%A0%91.png" style="zoom:50%;" />



**核心思想**：

- **可能的结果 (Universes)**：开始时，有9种可能的情况（硬币1是假的，硬币2是假的，...）。
- **信息获取**：每一次天平称重，根据其三种可能结果（左倾、右倾、平衡），我们将可能性的范围缩小到原来的1/3。
- **下界推导**：如果我们有 `U` 个可能的结果（Universes），而每次决策能将可能性减少为 `R` 种分支（这里 `R=3`），那么我们至少需要 `log_R(U)` 次决策。对于9个硬币，我们需要 `log₃(9) = 2` 次称重。

如果我们有10个硬币呢？我们需要 `log₃(10) > 2` 次称重。因此，用2次称重无法保证找出10枚硬币中的假币，因为两次称重最多只能产生 3^2=9 个不同的最终结果，不足以区分10种可能性。



#### 3.2 类比二：“小狗、小猫、小狗”游戏 (Puppy, Cat, Dog)

这个游戏将决策树的思想直接与排序问题联系起来。

**问题**：有三个不透明的盒子A、B、C，里面分别装着一只小狗、一只小猫和一只小狗，它们的重量各不相同（小狗 < 小猫 < 小狗）。你只有一个天平，目标是用最少的比较次数，确定A、B、C从轻到重的正确顺序。

**分析**：

1. 有多少种可能的结果 (Universes)？

   这三个盒子的重量排列组合共有` 3!=6` 种可能性：(A, B, C), (A, C, B), (B, A, C), (B, C, A), (C, A, B), (C, B, A)

2. 每次决策能提供多少信息？

   天平的一次比较 (例如，`A < B`?) 只有两种结果：是或否。这是一个二叉决策树。

3. 需要多少次决策？

   为了区分6种不同的可能性，决策树至少需要6个叶子节点。高度为 `H` 的二叉树最多有 2<sup>H</sup> 个叶子节点。

   - 2<sup>2</sup> = 4 < 6 (高度为2不够)
   - 2<sup>3</sup> = 8≥6 (高度为3足够)

   因此，最坏情况下至少需要3次比较。

推广到N个物品，总共有 **N!** 种可能的排列组合。我们的决策树必须有 N! 个叶子节点。因此，树的高度 `H`（即最少比较次数）必须满足：
$$
2^H \ge N! H \ge \log_2(N!)
$$
所以，解决这个N物品排列问题的比较次数下界是 Ω(log(N!))。



#### 3.3 连接类比与排序

“小狗、小猫、小狗”问题本质上就是一个排序问题。任何一个通用的比较排序算法都可以解决这个问题。因此，**排序问题的难度下界，一定不会低于“小狗、小猫、小狗”问题的难度下界**。

我们得出结论：**任何比较排序算法，在最坏情况下，都至少需要 Ω(log(N!)) 次比较**。





#### 3.4 最后的数学证明

现在的问题是，log(N!) 和我们熟悉的 N log N 之间是什么关系？

在课程的数学热身部分，我们证明了：
$$
log(N!) \in \Theta(N \log N)
$$
这意味着 log(N!) 和 N log N 的渐进增长率是相同的。

![](https://pic-go-image-1363881366.cos.ap-chengdu.myqcloud.com/Image/%E8%BE%B9%E7%95%8C%E8%AF%81%E6%98%8E.png)



### 4. 结论：排序算法的绝对最优性

我们把所有线索串联起来：

1. 任何比较排序算法的比较次数下界是 Ω(log(N!))。
2. 数学上证明了 log(N!) ∈ Θ(N log N)，所以 log(N!) 的增长率和 N log N 相同。
3. 因此，任何比较排序算法的比较次数下界是 Ω(N log N)。

我们已经找到了一个上界 O(N log N)（通过归并排序）和一个下界 Ω(N log N)（通过决策树理论）。当上界和下界相同时，我们称之为找到了一个**紧确界 (Tight Bound)**，用 Θ 表示。

**最终的结论是**：

**任何基于比较的排序算法，在最坏情况下的时间复杂度是 Θ(N log N)**。

这意味着，像**归并排序**和**堆排序**这样的算法，在渐进意义上已经达到了**绝对最优**。我们不可能发明出一种比它们更快的、只依赖比较和交换的通用排序算法了。



### 5. 代码解析：从实现看复杂度

我们回头看看两个基础排序的代码，来直观理解为什么它们是 Θ(N<sup>2</sup>)。



#### 1. 插入排序 (Insertion Sort) - (回顾)

```java
// [cite: 781-792]
public static void insSort(Comparable[] a) {
    int N = a.length;
    for (int i = 0; i < N; i++) {
        /* Swap item until it is in correct position. */
        for (int j = i; j > 0; j -= 1) {
            /* If left neighbor is less than me, stop. */
            if (less(a[j-1], a[j])) {
                break;
            }
            exch(a, j, j-1);
        }
    }
}
```

- **代码分析**：外层循环执行 `N` 次。内层循环在最坏情况（数组完全逆序）下，第 `i` 个元素需要向前比较和交换 `i` 次。总操作数大约是 `1 + 2 + ... + (N-1)`，这是一个等差数列求和，结果是`(N-1)N/2`，因此其时间复杂度为Θ (N<sup>2</sup>)。在最好情况（数组已排序），内层循环的 `if` 判断总为 `true`，`break` 会立即执行，总时间复杂度为 Θ(N)。



#### 2. 选择排序 (Selection Sort)

```java
// [cite: 767-776]
public static void selSort(Comparable[] a) {
    int N = a.length;
    for (int i = 0; i < N; i += 1) {
        int min = i;
        /** Find smallest item among unfixed items. */
        for (int j = i + 1; j < N; j += 1) {
            if (less(a[j], a[min])) {
                min = j;
            }
        }
        exch(a, i, min);
    }
}
```

- **代码分析**：
  - **外层循环 (`for i ...`)**：这个循环负责将排序好的元素“边界”从左向右推进。它会执行 `N` 次。
  - **内层循环 (`for j ...`)**：对于外层循环的每一次迭代 `i`，这个循环的目的是在数组未排序的部分（从索引 `i` 到 `N-1`）中找到最小的元素。
  - **比较次数**：当 `i=0` 时，内层循环比较 `N-1` 次；当 `i=1` 时，比较 `N-2` 次，以此类推。总比较次数是 `(N-1) + (N-2) + ... + 1 = (N-1)N/2`。这表明比较操作的次数是 Θ (N<sup>2</sup>)。
  - **交换次数**：`exch` (交换) 操作在内层循环之外，在外层循环之内。无论数组的初始顺序如何，每次外层循环都会执行一次交换。因此，总共有 `N` 次交换。
  - **结论**：选择排序的运行时间与输入数组的初始状态无关，它总是执行大约 N<sup>2</sup>/2 次比较和 `N` 次交换，所以其时间复杂度始终是 Θ (N<sup>2</sup>)。



#### 3. 归并排序 (Mergesort)

```java
// [cite: 841-848]
/** Mergesort. Can be optimized to avoid creation of subarrays. */
public static Comparable[] mergesort(Comparable[] input) {
    int N = input.length;
    if (N <= 1) return input; // Base case
    Comparable[] a = new Comparable[N/2];
    Comparable[] b = new Comparable[N - N/2];
    // Copy elements to subarrays (this part can be optimized)
    for (int i = 0; i < a.length; i += 1) a[i] = input[i];
    for (int i = 0; i < b.length; i += 1) b[i] = input[i + N/2];
    
    // Recursive calls and merge
    return merge(mergesort(a), mergesort(b));
}
```

- **代码分析**：

  - **核心思想**：这是一个典型的分治算法。它将数组分成两半，对每一半递归地调用自身，然后将两个已排序的子数组合并成一个完整的排序数组。

  - **`merge` 操作**：合并两个已排序的子数组需要遍历这两个子数组的所有元素。如果总共有 `k` 个元素，合并操作的时间和空间复杂度都是Θ(k)。

  - **递归树分析**：

    - 在递归树的**每一层**，所有 `merge` 操作处理的元素总数都是 `N`。例如，在第一层，两个大小为 `N/2` 的数组被合并，总工作量为 Θ(N)。在第二层，四个大小为 `N/4` 的数组被合并（分两次 `merge` 操作），总工作量仍然是 Θ(N)。
    - 递归树的**深度（或层数）** 是多少？每次递归调用都将问题规模减半，从 `N` 到 `N/2`，再到 `N/4`，直到大小为 1。这个过程需要 log<sub>2</sub> N 次，所以树的高度是 Θ(log N)。

  - **结论**：总运行时间是 **(每层的工作量) × (层数)**，

  - 即：
    $$
    \Theta(N) \times \Theta(\log N) = \Theta(N \log N)
    $$
    这是归并排序稳定且高效的关键。



#### 4. 堆排序 (Heapsort) (In-place 版本)

```java
// [cite: 905-921]
public static void sort(Comparable[] pq) {
    int N = pq.length;
    /* Phase 1: Heapify */
    for (int k = N/2; k >= 0; k -= 1) {
        sink(pq, k, N);
    }
    
    /* Phase 2: Sortdown */
    while (N > 1) {
        exch(pq, 0, N-1); // Swap max item to the end
        N -= 1;          // Decrease heap size
        sink(pq, 0, N);  // Restore heap property
    }
}
```

- **代码分析**：堆排序分为两个阶段。

  - **阶段 1：建堆 (Heapify)**

    - 第一个 `for` 循环将一个无序数组转换成一个最大堆 (Max Heap)。它从最后一个非叶子节点开始，向前对每个节点调用 `sink` 方法来确保堆的性质。
    - 虽然看起来像是 `N/2` 次调用 `sink` (每次 log N)，但通过更严谨的数学分析可以证明，这个建堆过程的总时间复杂度是线性的，即 Θ(N)。

  - **阶段 2：排序 (Sortdown)**

    - `while` 循环执行大约 `N` 次。

    - 在每次循环中，它将堆顶（当前数组中的最大元素）与堆的最后一个元素交换。这样，最大的元素就被放到了数组的末尾（正确的位置）。

    - 然后，它将堆的大小减一，并对新的堆顶调用 `sink` 方法来恢复堆的性质。`sink` 操作的时间复杂度与堆的高度成正比，即 Θ(\log k)，其中 `k` 是当前堆的大小。

    - 这个阶段的总时间是 

    - $$
      \sum_{k=2}^{N} \Theta(\log k)
      $$

    - 其结果是 Θ(N log N)。

  - **结论**：堆排序的总时间复杂度是两个阶段之和：

    - $$
      \Theta(N) + \Theta(N \log N) = \Theta(N \log N)
      $$

    - 由于它直接在原数组上操作，其空间复杂度为 Θ(1)。